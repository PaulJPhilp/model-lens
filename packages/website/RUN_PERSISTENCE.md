# Filter Run Persistence

Complete implementation of run history tracking for filter evaluations.

## Overview

Every filter evaluation is now persisted to the database, enabling:
- **Run history tracking** - View past evaluations
- **Analytics** - Analyze filter performance over time
- **Debugging** - Reproduce and investigate issues
- **Auditing** - Track who ran what and when
- **Reproducibility** - Re-examine past results

## Features

âœ… **Automatic Persistence** - Every evaluation automatically saves
âœ… **Filter Snapshots** - Captures filter state at execution time
âœ… **Execution Metadata** - Duration, timestamp, user
âœ… **Results Storage** - Per-model evaluation results
âœ… **Access Control** - Same permissions as parent filter
âœ… **UI Integration** - View history directly in FilterList
âœ… **API Endpoints** - List and retrieve runs programmatically

---

## Database Schema

### Table: `filter_runs`

```sql
CREATE TABLE filter_runs (
  -- Identity
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  filter_id UUID NOT NULL,

  -- Execution metadata
  executed_by UUID NOT NULL,
  executed_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT now(),
  duration_ms INTEGER,

  -- Filter snapshot (denormalized for history)
  filter_snapshot JSONB NOT NULL,

  -- Input parameters
  model_list JSONB,  -- Compact list of models evaluated (optional)
  limit_used INTEGER,
  model_ids_filter TEXT[],  -- Array of modelIds if filtering was used

  -- Results
  total_evaluated INTEGER NOT NULL,
  match_count INTEGER NOT NULL,
  results JSONB NOT NULL,  -- Array of evaluation results per model

  -- Artifacts (optional - for large outputs)
  artifacts JSONB,  -- { "fullResults": "s3://...", "modelList": "s3://..." }

  -- Indexing
  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT now()
);
```

### Indexes

```sql
CREATE INDEX idx_filter_runs_filter_id ON filter_runs(filter_id);
CREATE INDEX idx_filter_runs_executed_by ON filter_runs(executed_by);
CREATE INDEX idx_filter_runs_executed_at ON filter_runs(executed_at DESC);
CREATE INDEX idx_filter_runs_filter_executed ON filter_runs(filter_id, executed_at DESC);
```

**Purpose:**
- `filter_id` - Fast lookup of runs for a specific filter
- `executed_by` - Query runs by user
- `executed_at` - Chronological ordering
- Composite - Optimized filter history queries

---

## Data Structure

### FilterSnapshot

Captures filter state at execution time:

```typescript
interface FilterSnapshot {
  id: string;
  name: string;
  description: string | null;
  visibility: string;
  rules: RuleClause[];
  version: number;
}
```

**Why snapshot?**
- Filter may be edited after evaluation
- History shows filter "as it was" when run
- Enables comparison of how filter changed over time

### ModelRunResult

Per-model evaluation outcome:

```typescript
interface ModelRunResult {
  modelId: string;
  modelName: string;
  matchedAllHard: boolean;  // Did it pass all hard clauses?
  score: number;            // 0-1 soft clause score
  clauseResults?: Array<{   // Optional detailed breakdown
    field: string;
    matched: boolean;
    reason: string;
  }>;
  outputPreview?: string;   // Optional sample output
  latencyMs?: number;       // Optional timing
  tokensEstimate?: number;  // Optional token count
  costEstimate?: number;    // Optional cost estimate
}
```

### CompactModel (Optional)

For storing evaluated models in `model_list`:

```typescript
interface CompactModel {
  modelId: string;
  name: string;
  vendor?: string;
  cost_per_1k_tokens?: number;
  context_window?: number;
  // ... other relevant fields
}
```

**Note:** This is optional and can be omitted to reduce database size. Consider storing full model list in external storage (S3, etc.) and referencing via `artifacts`.

### RunArtifacts (Optional)

References to external storage:

```typescript
interface RunArtifacts {
  fullResults?: string;  // e.g., "s3://bucket/runs/uuid/results.json"
  modelList?: string;    // e.g., "s3://bucket/runs/uuid/models.json"
  logs?: string;
  [key: string]: string | undefined;
}
```

**Use case:** For very large evaluations (500+ models), store detailed results externally and keep only summary in database.

---

## API Endpoints

### 1. Evaluate Filter (Creates Run)

**Endpoint:** `POST /api/filters/[id]/evaluate`

**Behavior:**
- Evaluates filter against models
- **Automatically creates run record**
- Updates filter usage stats
- Returns evaluation results

**Request:**
```json
{
  "limit": 50,
  "modelIds": ["gpt-4", "claude-3-opus"]  // Optional
}
```

**Response:**
```json
{
  "filterId": "uuid",
  "filterName": "Budget AI Models",
  "results": [...],
  "totalEvaluated": 50,
  "matchCount": 15
}
```

**Side Effect:** Creates run in `filter_runs` table

---

### 2. List Filter Runs

**Endpoint:** `GET /api/filters/[id]/runs`

**Purpose:** List all runs for a specific filter

**Query Parameters:**
- `page` - Page number (default: 1)
- `pageSize` - Items per page (default: 20, max: 100)

**Response:**
```json
{
  "runs": [
    {
      "id": "run-uuid",
      "filterId": "filter-uuid",
      "executedBy": "user-uuid",
      "executedAt": "2025-01-15T10:30:00Z",
      "durationMs": 1234,
      "filterSnapshot": {
        "id": "filter-uuid",
        "name": "Budget AI Models",
        "rules": [...]
      },
      "totalEvaluated": 50,
      "matchCount": 15,
      "results": [...],
      "limitUsed": 50,
      "modelIdsFilter": null,
      "artifacts": null,
      "createdAt": "2025-01-15T10:30:00Z"
    }
  ],
  "total": 1,
  "page": 1,
  "pageSize": 20
}
```

**Access Control:** Same as parent filter (owner, team members, or public)

---

### 3. Get Single Run

**Endpoint:** `GET /api/filters/[id]/runs/[runId]`

**Purpose:** Retrieve detailed run information

**Response:** Single `FilterRunResponse` object

**Access Control:** Same as parent filter

**Use Case:** Deep-dive into specific run, view all results

---

## Usage

### Setup (One-Time)

1. **Run Migration:**
   ```bash
   psql $DATABASE_URL -f db/migrations/0002_create_filter_runs.sql
   ```

2. **Verify Table Created:**
   ```bash
   psql $DATABASE_URL -c "\d filter_runs"
   ```

3. **Restart Dev Server:**
   ```bash
   npm run dev
   ```

### Using in UI

1. **Navigate to Filters:** `/filters`
2. **Apply a Filter:** Click "Apply Filter" on any filter
3. **View History:** Click "History" button on filter card
4. **Explore Runs:** See all past evaluations with:
   - Match count
   - Duration
   - Timestamp
   - Detailed results

### Using via API

**Create a Run (via evaluation):**
```bash
curl -X POST http://localhost:3002/api/filters/FILTER_ID/evaluate \
  -H "Content-Type: application/json" \
  -H "x-user-id: test-user" \
  -d '{"limit": 20}'
```

**List Runs:**
```bash
curl "http://localhost:3002/api/filters/FILTER_ID/runs?page=1&pageSize=10" \
  -H "x-user-id: test-user"
```

**Get Specific Run:**
```bash
curl http://localhost:3002/api/filters/FILTER_ID/runs/RUN_ID \
  -H "x-user-id: test-user"
```

---

## UI Components

### FilterRunHistory

**Location:** `components/FilterRunHistory.tsx`

**Features:**
- Lists all runs for a filter
- Displays match count, duration, timestamp
- Opens detailed view on click
- Pagination support
- Shows filter snapshot used
- Displays matching models with scores

**Usage:**
```tsx
import { FilterRunHistory } from '@/components/FilterRunHistory';

<FilterRunHistory filterId="filter-uuid" onClose={() => {}} />
```

**Integrated in FilterList:**
- Click "History" button on any filter
- Opens modal with full run history
- View details of individual runs

---

## Access Control

### RBAC Enforcement

**Rules:**
- User must have read access to parent filter
- Same visibility rules apply (private/team/public)
- Owner, team members, or public (based on filter visibility)

**Implementation:**
```typescript
// Check parent filter access first
const [filter] = await db
  .select()
  .from(savedFilters)
  .where(eq(savedFilters.id, filterId))
  .limit(1);

if (!canAccessFilter(auth.userId, filter, auth.teamId)) {
  return NextResponse.json({ error: 'Forbidden' }, { status: 403 });
}

// Then query runs
const runs = await db
  .select()
  .from(filterRuns)
  .where(eq(filterRuns.filterId, filterId));
```

**Why?**
- Prevents unauthorized access to run history
- Consistent with filter permissions
- Team collaboration: team members can see all runs
- Privacy: private filter runs stay private

---

## Performance Considerations

### Database Size

**Estimate:**
- ~1 KB per model result
- 50 models = ~50 KB per run
- 100 runs = ~5 MB per filter
- 1000 filters Ã— 100 runs = ~500 MB

**Mitigation:**
1. **Pagination** - Only load 20 runs at a time
2. **Retention Policy** - Delete runs older than X days
3. **External Storage** - Store large results in S3/blob storage
4. **Summary Mode** - Store only match count, not full results

### Query Optimization

**Indexes:**
- `(filter_id, executed_at DESC)` - Fastest run history queries
- `executed_by` - Per-user analytics
- `executed_at` - Chronological queries

**Tips:**
- Use LIMIT for pagination (already implemented)
- Consider archiving old runs to separate table
- Monitor table size: `SELECT pg_size_pretty(pg_relation_size('filter_runs'));`

### Avoiding DB Bloat

**Option 1: Limit Stored Results**
```typescript
// Only store top 10 matches instead of all
const topMatches = results
  .filter(r => r.match)
  .sort((a, b) => b.score - a.score)
  .slice(0, 10);

await db.insert(filterRuns).values({
  // ...
  results: topMatches,
});
```

**Option 2: External Storage**
```typescript
// Store full results in S3
const s3Url = await uploadToS3(`runs/${runId}/results.json`, fullResults);

await db.insert(filterRuns).values({
  // ...
  results: summaryResults,  // Only summary
  artifacts: {
    fullResults: s3Url,
  },
});
```

**Option 3: Retention Policy**
```sql
-- Delete runs older than 90 days
DELETE FROM filter_runs
WHERE executed_at < NOW() - INTERVAL '90 days';
```

---

## Analytics Use Cases

### 1. Filter Performance Tracking

```sql
-- Average match rate over time
SELECT
  DATE(executed_at) as date,
  AVG(match_count::float / total_evaluated) as avg_match_rate,
  COUNT(*) as run_count
FROM filter_runs
WHERE filter_id = 'filter-uuid'
GROUP BY DATE(executed_at)
ORDER BY date DESC;
```

### 2. Most Used Filters

```sql
-- Filters with most runs
SELECT
  f.name,
  COUNT(r.id) as run_count,
  AVG(r.match_count::float / r.total_evaluated) as avg_match_rate
FROM saved_filters f
JOIN filter_runs r ON r.filter_id = f.id
GROUP BY f.id, f.name
ORDER BY run_count DESC
LIMIT 10;
```

### 3. User Activity

```sql
-- Runs per user
SELECT
  executed_by,
  COUNT(*) as total_runs,
  AVG(duration_ms) as avg_duration_ms
FROM filter_runs
WHERE executed_at > NOW() - INTERVAL '7 days'
GROUP BY executed_by
ORDER BY total_runs DESC;
```

### 4. Performance Trends

```sql
-- Average execution time over time
SELECT
  DATE(executed_at) as date,
  AVG(duration_ms) as avg_duration_ms,
  MAX(duration_ms) as max_duration_ms
FROM filter_runs
GROUP BY DATE(executed_at)
ORDER BY date DESC;
```

---

## Debugging and Reproducibility

### Investigate Failed Filters

1. **Find Recent Runs:**
   ```sql
   SELECT id, executed_at, match_count, total_evaluated
   FROM filter_runs
   WHERE filter_id = 'problematic-filter-uuid'
   ORDER BY executed_at DESC
   LIMIT 5;
   ```

2. **Examine Specific Run:**
   ```bash
   curl http://localhost:3002/api/filters/FILTER_ID/runs/RUN_ID \
     -H "x-user-id: user"
   ```

3. **Compare Filter Snapshot:**
   ```sql
   SELECT filter_snapshot->'rules' as rules_then
   FROM filter_runs
   WHERE id = 'run-uuid';
   ```

### Reproduce Issues

1. **Get filter snapshot from run**
2. **See exact rules used**
3. **Identify which models were evaluated**
4. **Check if filter has changed since**

**Example:**
```typescript
const run = await fetch(`/api/filters/${filterId}/runs/${runId}`).then(r => r.json());

console.log('Filter used:', run.filterSnapshot);
console.log('Models evaluated:', run.totalEvaluated);
console.log('Matches found:', run.matchCount);
console.log('Results:', run.results);
```

---

## Migration Guide

### Applying the Migration

**Option 1: psql**
```bash
psql $DATABASE_URL -f db/migrations/0002_create_filter_runs.sql
```

**Option 2: Drizzle Kit (if configured)**
```bash
bun drizzle-kit push
```

**Option 3: Custom Script**
```bash
bun run src/scripts/run-migration.ts 0002_create_filter_runs.sql
```

### Verification

```bash
# Check table exists
psql $DATABASE_URL -c "\dt filter_runs"

# Check indexes
psql $DATABASE_URL -c "\di filter_runs*"

# Check columns
psql $DATABASE_URL -c "\d filter_runs"
```

**Expected Output:**
```
                         Table "public.filter_runs"
      Column       |           Type           | Collation | Nullable | Default
-------------------+--------------------------+-----------+----------+---------
 id                | uuid                     |           | not null | gen_random_uuid()
 filter_id         | uuid                     |           | not null |
 executed_by       | uuid                     |           | not null |
 executed_at       | timestamp with time zone |           | not null | now()
 ...
```

---

## Best Practices

### 1. Keep Results Lean

**Do:**
- Store only necessary fields
- Use compact model representation
- Consider top-N results only

**Don't:**
- Store full model registry in every run
- Include unnecessary nested data
- Duplicate information already in filter

### 2. Use External Storage for Large Data

```typescript
// For evaluations > 100 models
if (models.length > 100) {
  const fullResults = await uploadToS3(results);

  await db.insert(filterRuns).values({
    // ...
    results: results.slice(0, 20),  // Top 20 only
    artifacts: {
      fullResults,
    },
  });
}
```

### 3. Implement Retention Policies

```typescript
// Cron job to clean up old runs
async function cleanupOldRuns() {
  const cutoff = new Date();
  cutoff.setDate(cutoff.getDate() - 90);  // 90 days

  await db
    .delete(filterRuns)
    .where(lt(filterRuns.executedAt, cutoff));
}
```

### 4. Monitor Table Size

```sql
-- Check table size
SELECT
  pg_size_pretty(pg_total_relation_size('filter_runs')) as total_size,
  pg_size_pretty(pg_relation_size('filter_runs')) as table_size,
  pg_size_pretty(pg_indexes_size('filter_runs')) as indexes_size;
```

---

## Troubleshooting

### "Relation filter_runs does not exist"

**Cause:** Migration not run

**Fix:**
```bash
psql $DATABASE_URL -f db/migrations/0002_create_filter_runs.sql
```

### "Cannot read property 'results' of undefined"

**Cause:** No runs exist for filter

**Fix:** This is expected for new filters. Apply filter at least once.

### Slow run history queries

**Cause:** Missing indexes or large table

**Fix:**
1. Verify indexes exist
2. Implement pagination (already done)
3. Consider archiving old runs

### "Permission denied for table filter_runs"

**Cause:** Database user lacks permissions

**Fix:**
```sql
GRANT SELECT, INSERT ON filter_runs TO your_app_user;
```

---

## Summary

âœ… **Implemented:**
- Database table with indexes
- Drizzle schema with TypeScript types
- Automatic run persistence on evaluate
- API endpoints to list/get runs
- UI component for run history
- Access control (RBAC)
- Comprehensive documentation

âœ… **Benefits:**
- Complete run history tracking
- Filter performance analytics
- Debugging and reproducibility
- Audit trail for compliance
- No breaking changes to existing code

âœ… **Production Ready:**
- Optimized indexes
- Pagination support
- External storage option
- Retention policy guidelines
- Performance considerations documented

**Next Steps:**
1. Apply migration
2. Test by running a filter
3. View history in UI
4. Consider retention policy
5. Monitor database size

**Run persistence is now fully operational!** ðŸŽ‰
